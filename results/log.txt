[2024-06-27 13:50:09] ðŸŒŸ Training
[2024-06-27 13:50:09] Load configuration file config.yml:

seed: 0
save_interval: 0
vocab_size: 16384
total_batch_size: 65536
batch_size: 16
max_epoch: 30
optimizer_args:
  lr: 0.0003
  betas:
  - 0.9
  - 0.999
  eps: 1.0e-08
  weight_decay: 0.01
scheduler_args:
  T_0: 30
  eta_min: 3.0e-05
generation_args:
  temperature: 1.0
  top_p: 1.0
model_args:
  d_model: 512
  n_heads: 8
  n_layers: 6
  dropout: 0.1
  max_sequence_length: 1024

[2024-06-27 13:50:11] Built a model with 69,307,392 parameters (device: cuda:0)
[2024-06-27 13:50:14] Gradient accumulation step: 1
[2024-06-27 14:10:18] Epoch 1 | train_loss 6.5568 | lr 0.00029705 | pad_percent 49.08% | grad_norm 0.6090 | duration 1202.3740s | token/sec 111300
[2024-06-27 14:10:53] Epoch 1 | valid_loss 6.1089 <------------------------------ best validation loss
[2024-06-27 14:30:55] Epoch 2 | train_loss 5.4915 | lr 0.00029339 | pad_percent 61.67% | grad_norm 0.7577 | duration 1199.9879s | token/sec 111521
[2024-06-27 14:31:30] Epoch 2 | valid_loss 5.5169 <------------------------------ best validation loss
[2024-06-27 14:51:34] Epoch 3 | train_loss 4.8933 | lr 0.00028833 | pad_percent 57.38% | grad_norm 0.8297 | duration 1197.9546s | token/sec 111710
[2024-06-27 14:52:09] Epoch 3 | valid_loss 5.0927 <------------------------------ best validation loss
[2024-06-27 15:12:17] Epoch 4 | train_loss 4.4737 | lr 0.00028192 | pad_percent 32.38% | grad_norm 0.8891 | duration 1201.6658s | token/sec 111365
[2024-06-27 15:12:52] Epoch 4 | valid_loss 4.7772 <------------------------------ best validation loss
[2024-06-27 15:32:57] Epoch 5 | train_loss 4.1125 | lr 0.00027422 | pad_percent 42.22% | grad_norm 0.9502 | duration 1198.7235s | token/sec 111639
[2024-06-27 15:33:32] Epoch 5 | valid_loss 4.4248 <------------------------------ best validation loss
[2024-06-27 15:53:34] Epoch 6 | train_loss 3.8053 | lr 0.00026533 | pad_percent 38.20% | grad_norm 0.9669 | duration 1195.6727s | token/sec 111924
[2024-06-27 15:54:09] Epoch 6 | valid_loss 4.1468 <------------------------------ best validation loss
[2024-06-27 16:14:19] Epoch 7 | train_loss 3.5166 | lr 0.00025534 | pad_percent 47.85% | grad_norm 0.9214 | duration 1203.3622s | token/sec 111208
[2024-06-27 16:14:54] Epoch 7 | valid_loss 3.8650 <------------------------------ best validation loss
[2024-06-27 16:35:04] Epoch 8 | train_loss 3.2612 | lr 0.00024436 | pad_percent 35.07% | grad_norm 0.9063 | duration 1202.7074s | token/sec 111269
[2024-06-27 16:35:38] Epoch 8 | valid_loss 3.6038 <------------------------------ best validation loss
[2024-06-27 16:55:41] Epoch 9 | train_loss 3.0697 | lr 0.00023251 | pad_percent 46.62% | grad_norm 0.8858 | duration 1196.0385s | token/sec 111889
[2024-06-27 16:56:16] Epoch 9 | valid_loss 3.4786 <------------------------------ best validation loss
[2024-06-27 17:16:25] Epoch 10 | train_loss 2.9265 | lr 0.00021992 | pad_percent 59.70% | grad_norm 0.8553 | duration 1202.4047s | token/sec 111297
[2024-06-27 17:16:59] Epoch 10 | valid_loss 3.3639 <------------------------------ best validation loss
[2024-06-27 17:37:06] Epoch 11 | train_loss 2.7995 | lr 0.00020672 | pad_percent 48.64% | grad_norm 0.8209 | duration 1199.8905s | token/sec 111530
[2024-06-27 17:37:41] Epoch 11 | valid_loss 3.2768 <------------------------------ best validation loss
[2024-06-27 17:57:47] Epoch 12 | train_loss 2.6995 | lr 0.00019307 | pad_percent 37.28% | grad_norm 0.7906 | duration 1199.7708s | token/sec 111541
[2024-06-27 17:58:22] Epoch 12 | valid_loss 3.2113 <------------------------------ best validation loss
[2024-06-27 18:18:31] Epoch 13 | train_loss 2.6215 | lr 0.00017912 | pad_percent 28.16% | grad_norm 0.7714 | duration 1202.9920s | token/sec 111243
[2024-06-27 18:19:06] Epoch 13 | valid_loss 3.1763 <------------------------------ best validation loss
[2024-06-27 18:39:12] Epoch 14 | train_loss 2.5523 | lr 0.00016501 | pad_percent 67.93% | grad_norm 0.7555 | duration 1198.9911s | token/sec 111614
[2024-06-27 18:39:46] Epoch 14 | valid_loss 3.1480 <------------------------------ best validation loss
[2024-06-27 18:59:55] Epoch 15 | train_loss 2.4983 | lr 0.00015090 | pad_percent 48.36% | grad_norm 0.7478 | duration 1202.2162s | token/sec 111314
[2024-06-27 19:00:30] Epoch 15 | valid_loss 3.1182 <------------------------------ best validation loss
[2024-06-27 19:20:37] Epoch 16 | train_loss 2.4504 | lr 0.00013694 | pad_percent 59.47% | grad_norm 0.7446 | duration 1200.0302s | token/sec 111517
[2024-06-27 19:21:11] Epoch 16 | valid_loss 3.1107 <------------------------------ best validation loss
[2024-06-27 19:41:16] Epoch 17 | train_loss 2.4077 | lr 0.00012329 | pad_percent 46.89% | grad_norm 0.7404 | duration 1198.6953s | token/sec 111641
[2024-06-27 19:41:51] Epoch 17 | valid_loss 3.0902 <------------------------------ best validation loss
[2024-06-27 20:01:56] Epoch 18 | train_loss 2.3692 | lr 0.00011010 | pad_percent 24.47% | grad_norm 0.7420 | duration 1198.5548s | token/sec 111654
[2024-06-27 20:02:31] Epoch 18 | valid_loss 3.0956
[2024-06-27 20:22:28] Epoch 19 | train_loss 2.3339 | lr 0.00009751 | pad_percent 37.69% | grad_norm 0.7406 | duration 1193.3752s | token/sec 112139
[2024-06-27 20:23:02] Epoch 19 | valid_loss 3.0792 <------------------------------ best validation loss
[2024-06-27 20:43:06] Epoch 20 | train_loss 2.3043 | lr 0.00008565 | pad_percent 43.82% | grad_norm 0.7432 | duration 1196.9903s | token/sec 111800
[2024-06-27 20:43:41] Epoch 20 | valid_loss 3.0778 <------------------------------ best validation loss
[2024-06-27 21:03:51] Epoch 21 | train_loss 2.2784 | lr 0.00007467 | pad_percent 34.03% | grad_norm 0.7452 | duration 1203.5113s | token/sec 111195
[2024-06-27 21:04:25] Epoch 21 | valid_loss 3.0778 <------------------------------ best validation loss
[2024-06-27 21:24:34] Epoch 22 | train_loss 2.2504 | lr 0.00006468 | pad_percent 44.89% | grad_norm 0.7478 | duration 1201.8180s | token/sec 111351
[2024-06-27 21:25:08] Epoch 22 | valid_loss 3.0750 <------------------------------ best validation loss
[2024-06-27 21:45:15] Epoch 23 | train_loss 2.2301 | lr 0.00005579 | pad_percent 59.08% | grad_norm 0.7495 | duration 1199.8344s | token/sec 111535
[2024-06-27 21:45:49] Epoch 23 | valid_loss 3.0820
[2024-06-27 22:05:56] Epoch 24 | train_loss 2.2084 | lr 0.00004809 | pad_percent 41.60% | grad_norm 0.7519 | duration 1203.4503s | token/sec 111200
[2024-06-27 22:06:31] Epoch 24 | valid_loss 3.0720 <------------------------------ best validation loss
[2024-06-27 22:26:35] Epoch 25 | train_loss 2.1923 | lr 0.00004167 | pad_percent 53.67% | grad_norm 0.7552 | duration 1197.2860s | token/sec 111773
[2024-06-27 22:27:09] Epoch 25 | valid_loss 3.0687 <------------------------------ best validation loss
[2024-06-27 22:47:18] Epoch 26 | train_loss 2.1774 | lr 0.00003661 | pad_percent 54.24% | grad_norm 0.7572 | duration 1202.4031s | token/sec 111297
[2024-06-27 22:47:53] Epoch 26 | valid_loss 3.0743
[2024-06-27 23:08:00] Epoch 27 | train_loss 2.1663 | lr 0.00003295 | pad_percent 31.98% | grad_norm 0.7592 | duration 1203.8801s | token/sec 111160
[2024-06-27 23:08:35] Epoch 27 | valid_loss 3.0741
[2024-06-27 23:28:39] Epoch 28 | train_loss 2.1569 | lr 0.00003074 | pad_percent 41.11% | grad_norm 0.7625 | duration 1200.9128s | token/sec 111435
[2024-06-27 23:29:14] Epoch 28 | valid_loss 3.0817
[2024-06-27 23:49:16] Epoch 29 | train_loss 2.1500 | lr 0.00003000 | pad_percent 60.82% | grad_norm 0.7639 | duration 1198.7768s | token/sec 111634
[2024-06-27 23:49:51] Epoch 29 | valid_loss 3.0771
[2024-06-28 00:09:57] Epoch 30 | train_loss 2.3908 | lr 0.00029926 | pad_percent 40.66% | grad_norm 0.8259 | duration 1202.8971s | token/sec 111251
[2024-06-28 00:10:32] Epoch 30 | valid_loss 3.1182
[2024-06-28 00:10:35] Training finished!
[2024-06-28 12:08:12] ðŸŒŸ Generation (device: mps)
[2024-06-28 12:08:12] Load generation configuration:

temperature: 1.0
top_p: 0.3

[2024-06-28 12:08:14] Input:
æˆ‘è§é’å±±å¤šå¦©åªšï¼Œé’å±±è§æˆ‘åº”å¦‚æ˜¯ã€‚
[2024-06-28 12:08:14] Output:
æˆ‘çœ‹åˆ°é’å±±å¾ˆå¦©åªšï¼Œé’å±±çœ‹æˆ‘åº”è¯¥å¦‚æ­¤ã€‚
[2024-06-28 12:09:01] ðŸŒŸ Generation (device: mps)
[2024-06-28 12:09:01] Load generation configuration:

temperature: 1.0
top_p: 0.3

[2024-06-28 12:09:55] Input:
è¯è¯´å¤©ä¸‹å¤§åŠ¿ï¼Œåˆ†ä¹…å¿…åˆï¼Œåˆä¹…å¿…åˆ†ã€‚å‘¨æœ«ä¸ƒå›½åˆ†äº‰ï¼Œå¹¶å…¥äºŽç§¦ã€‚åŠç§¦ç­ä¹‹åŽï¼Œæ¥šã€æ±‰åˆ†äº‰ï¼Œåˆå¹¶å…¥äºŽæ±‰ã€‚æ±‰æœè‡ªé«˜ç¥–æ–©ç™½è›‡è€Œèµ·ä¹‰ï¼Œä¸€ç»Ÿå¤©ä¸‹ï¼ŒåŽæ¥å…‰æ­¦ä¸­å…´ï¼Œä¼ è‡³çŒ®å¸ï¼Œé‚åˆ†ä¸ºä¸‰å›½ã€‚æŽ¨å…¶è‡´ä¹±ä¹‹ç”±ï¼Œæ®†å§‹äºŽæ¡“ã€çµäºŒå¸ã€‚æ¡“å¸ç¦é”¢å–„ç±»ï¼Œå´‡ä¿¡å®¦å®˜ã€‚åŠæ¡“å¸å´©ï¼Œçµå¸å³ä½ï¼Œå¤§å°†å†›çª¦æ­¦ã€å¤ªå‚…é™ˆè•ƒå…±ç›¸è¾…ä½ã€‚æ—¶æœ‰å®¦å®˜æ›¹èŠ‚ç­‰å¼„æƒï¼Œçª¦æ­¦ã€é™ˆè•ƒè°‹è¯›ä¹‹ï¼Œæœºäº‹ä¸å¯†ï¼Œåä¸ºæ‰€å®³ï¼Œä¸­æ¶“è‡ªæ­¤æ„ˆæ¨ªã€‚
[2024-06-28 12:09:55] Output:
è¯è¯´å¤©ä¸‹å¤§åŠ¿ï¼Œåˆ†å¹´ä¸€å®šç»“åˆï¼Œæ—¶é—´ä¹…äº†ä¸€å®šåˆ†æˆä¸¤åŠã€‚å‘¨æœæœ«æœŸä¸ƒå›½åˆ†æˆä¸¤åŠï¼Œåˆå¹¶å…¥ç§¦ã€‚ç­‰åˆ°ç§¦æœç­äº¡ä¹‹åŽï¼Œæ¥šæ±‰åˆ†è£‚äº‰å¤ºï¼Œåˆéƒ½å½’äºŽæ±‰æœã€‚æ±‰æœè‡ªé«˜ç¥–æ–©ç™½è›‡èµ·ä¹‰ï¼Œç»Ÿä¸€å…¨å›½ï¼ŒåŽæ¥å…‰æ­¦ä¸­å…´ï¼Œä¼ åˆ°æ±‰çŒ®å¸ï¼ŒäºŽæ˜¯åˆ†ä¸ºä¸‰å›½ã€‚æŽ¨ç©¶å¯¼è‡´ç¥¸ä¹±çš„æ ¹æºï¼Œå¤§æ¦‚å¼€å§‹äºŽæ¡“å¸ã€çµå¸äºŒå¸ã€‚æ¡“å¸ç¦é”¢å–„ç±»ï¼Œå°Šå´‡ä¿¡ä»»å®¦å®˜ã€‚æ¡“å¸æ¡“å¸é©¾å´©ï¼Œçµå¸å³ä½ï¼Œå¤§å°†å†›çª¦æ­¦ã€å¤ªå‚…é™ˆè•ƒå…±åŒè¾…ä½ã€‚å½“æ—¶å®¦å®˜æ›¹èŠ‚ç­‰äººçŽ©å¼„æƒåŠ¿ï¼Œçª¦æ­¦ã€é™ˆè•ƒé˜´è°‹è¯›æ€ä»–ä»¬ï¼Œæ›¹èŠ‚ç­‰äººçš„é˜´è°‹ä¸ä¸¥å¯†ï¼Œåè€Œè¢«ä»–ä»¬æ€å®³ï¼Œå®¦å®˜ä»¬ä»Žæ­¤æ›´åŠ éª„æ¨ªã€‚
